{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "70d915ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Input, LSTM, Reshape, Lambda, RepeatVector, Conv2D, MaxPooling2D, Flatten\n",
    "from tensorflow.keras.initializers import glorot_uniform\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "import pandas as pd \n",
    "import csv"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0c645f0b",
   "metadata": {},
   "source": [
    "We load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "319aefa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=np.load('train_x.npy')\n",
    "x_test=np.load('test_x.npy')\n",
    "y_train=np.load('train_y.npy')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e53a023b",
   "metadata": {},
   "source": [
    "We flatten the data to have on the first line every pixel and the other columns are the 102 spectral band values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5c5c64c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_x_flatten = x_train.reshape(x_train.shape[2],x_train.shape[0]*x_train.shape[1]).T\n",
    "test_set_x_flatten = x_test.reshape(x_test.shape[2],x_test.shape[0]*x_test.shape[1]).T\n",
    "train_set_y_flatten = y_train.reshape(1,x_train.shape[0]*x_train.shape[1]).T"
   ]
  },
  {
   "cell_type": "raw",
   "id": "17a251e8",
   "metadata": {},
   "source": [
    "We store the number of classes and we transform the y vector in order to represent every class as a vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ac446add",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes=int(max(train_set_y_flatten)[0]+1)\n",
    "y= to_categorical(train_set_y_flatten,num_classes)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c0c64498",
   "metadata": {},
   "source": [
    "We split the train vectors into a train and a validation vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "18546b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "xt = train_set_x_flatten[0:int(len(train_set_x_flatten)*0.7),:]\n",
    "xv = train_set_x_flatten[int(len(train_set_x_flatten)*0.7):len(train_set_x_flatten),:]\n",
    "yt = y[0:int(len(y)*0.7),:]\n",
    "yv = y[int(len(y)*0.7):len(y),:]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d96d0521",
   "metadata": {},
   "source": [
    "We build the neural networks. Since we want to sutdy every pixel, we flatten and use relu instead of looking for dimensional reduction methods like convolutions. On the input, we lay down 103 neurons since one pixel is described by 103 values. We then procede to add several dense relus with cascading sizes. We did this part by testing different configurations and we stay with the best accuracy model. In the end, we put a final dense with a softmax activation. Since we want to classify these pixel, the softmax will take care of it. We registered before the number of classes in the dataset to put the dimension of our output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ceb95b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(103, activation=\"relu\"))\n",
    "model.add(Dense(80, activation=\"relu\"))\n",
    "model.add(Dense(60, activation=\"relu\"))\n",
    "model.add(Dense(40, activation=\"relu\"))\n",
    "model.add(Dense(20, activation=\"relu\"))\n",
    "model.add(Dense(num_classes, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2e2f06a0",
   "metadata": {},
   "source": [
    "We compile and we train the system on the train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "019c0103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "145/145 [==============================] - 1s 2ms/step - loss: 5.5653 - acc: 0.7522 - val_loss: 1.0685 - val_acc: 0.7895\n",
      "Epoch 2/20\n",
      "145/145 [==============================] - 0s 1ms/step - loss: 0.3508 - acc: 0.8354 - val_loss: 0.7105 - val_acc: 0.7940\n",
      "Epoch 3/20\n",
      "145/145 [==============================] - 0s 1ms/step - loss: 0.2009 - acc: 0.8480 - val_loss: 0.5558 - val_acc: 0.8015\n",
      "Epoch 4/20\n",
      "145/145 [==============================] - 0s 1ms/step - loss: 0.1524 - acc: 0.8566 - val_loss: 0.4607 - val_acc: 0.8174\n",
      "Epoch 5/20\n",
      "145/145 [==============================] - 0s 1ms/step - loss: 0.1302 - acc: 0.8617 - val_loss: 0.4023 - val_acc: 0.8256\n",
      "Epoch 6/20\n",
      "145/145 [==============================] - 0s 1ms/step - loss: 0.1187 - acc: 0.8645 - val_loss: 0.3721 - val_acc: 0.8304\n",
      "Epoch 7/20\n",
      "145/145 [==============================] - 0s 1ms/step - loss: 0.1116 - acc: 0.8661 - val_loss: 0.3597 - val_acc: 0.8282\n",
      "Epoch 8/20\n",
      "145/145 [==============================] - 0s 1ms/step - loss: 0.1078 - acc: 0.8665 - val_loss: 0.3497 - val_acc: 0.8300\n",
      "Epoch 9/20\n",
      "145/145 [==============================] - 0s 1ms/step - loss: 0.1046 - acc: 0.8667 - val_loss: 0.3448 - val_acc: 0.8314\n",
      "Epoch 10/20\n",
      "145/145 [==============================] - 0s 1ms/step - loss: 0.1029 - acc: 0.8669 - val_loss: 0.3440 - val_acc: 0.8312\n",
      "Epoch 11/20\n",
      "145/145 [==============================] - 0s 1ms/step - loss: 0.1013 - acc: 0.8669 - val_loss: 0.3474 - val_acc: 0.8316\n",
      "Epoch 12/20\n",
      "145/145 [==============================] - 0s 1ms/step - loss: 0.1010 - acc: 0.8668 - val_loss: 0.3473 - val_acc: 0.8312\n",
      "Epoch 13/20\n",
      "145/145 [==============================] - 0s 1ms/step - loss: 0.1001 - acc: 0.8669 - val_loss: 0.3380 - val_acc: 0.8316\n",
      "Epoch 14/20\n",
      "145/145 [==============================] - 0s 1ms/step - loss: 0.0996 - acc: 0.8669 - val_loss: 0.3282 - val_acc: 0.8315\n",
      "Epoch 15/20\n",
      "145/145 [==============================] - 0s 1ms/step - loss: 0.0986 - acc: 0.8669 - val_loss: 0.3302 - val_acc: 0.8313\n",
      "Epoch 16/20\n",
      "145/145 [==============================] - 0s 1ms/step - loss: 0.0981 - acc: 0.8670 - val_loss: 0.3367 - val_acc: 0.8301\n",
      "Epoch 17/20\n",
      "145/145 [==============================] - 0s 1ms/step - loss: 0.0984 - acc: 0.8669 - val_loss: 0.3281 - val_acc: 0.8241\n",
      "Epoch 18/20\n",
      "145/145 [==============================] - 0s 1ms/step - loss: 0.0982 - acc: 0.8668 - val_loss: 0.3028 - val_acc: 0.8316\n",
      "Epoch 19/20\n",
      "145/145 [==============================] - 0s 1ms/step - loss: 0.0969 - acc: 0.8670 - val_loss: 0.3088 - val_acc: 0.8315\n",
      "Epoch 20/20\n",
      "145/145 [==============================] - 0s 1ms/step - loss: 0.0968 - acc: 0.8670 - val_loss: 0.2910 - val_acc: 0.8312\n"
     ]
    }
   ],
   "source": [
    "batch_size = 512\n",
    "epoch = 20\n",
    "model.compile(optimizer=\"Adam\",loss='binary_crossentropy',metrics=['acc'])\n",
    "output=model.fit(xt,yt,epochs=epoch, batch_size=batch_size, validation_data=(xv,yv))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "aaf25e2f",
   "metadata": {},
   "source": [
    "We plot the loss of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f0904146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x281d0919be0>]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAD4CAYAAADFAawfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAaNElEQVR4nO3dfZAcd33n8fd3Hlc7s3rYB9uyZSycUHEcbMBsSMAJ54BDjK3CeaocSUhcie8UOKiCq9xduOKKkEpdVXIXXImvUqQM+CBAICTB4Bg7geMhDqnYYeXIkoUdbCgbZMnW6lnaXe3uzHzvj+6Z7RnN7I60OzPd059X1VQ/zsx3WqPP9P66f93m7oiISHxlBl2AiIisTkEtIhJzCmoRkZhTUIuIxJyCWkQk5nK9eNHJyUnfuXNnL15aRGQo7dmz56i7T7Vb1pOg3rlzJzMzM714aRGRoWRmz3VapqYPEZGYU1CLiMScglpEJOYU1CIiMaegFhGJOQW1iEjMKahFRGIuNkHt7tz9laf5h2/PDroUEZFYiU1Qmxkffvi7fO2pI4MuRUQkVmIT1AAT5QLH5pYGXYaISKzEKqjHSwWOzy0OugwRkViJVVBPlIscO6s9ahGRqFgF9WS5wFEFtYhIk1gF9USpyIn5JWo13XBXRKQuVkE9XipQrTmnFpYHXYqISGzEKqgnygUAjumAoohIQ6yCerJcBFA7tYhIRKyCurFHraAWEWmIVVCPl4Kg1rnUIiIr4hXUo0FQq+lDRGRFrII6l82wbTSvg4kiIhGxCmpQ70QRkVbxC+qSLswkIhIVv6AuFzh2Vk0fIiJ18QvqUlF71CIiEfEL6nKBk/PLLFdrgy5FRCQWct2sZGbPAmeAKlBx9+leFTQR9k48Mb/EJWMjvXobEZHE6CqoQz/l7kd7VkloorTSO1FBLSISx6aPkrqRi4hEdRvUDnzJzPaY2e52K5jZbjObMbOZ2dmLv5N4velDnV5ERALdBvWN7n4D8GbgnWb2+tYV3P0ed5929+mpqamLLmiyrG7kIiJRXQW1ux8Kh0eA+4DX9KqgzSN5shnThZlEREJrBrWZlcxsrD4OvAl4omcFZYzxUkFt1CIioW7O+rgUuM/M6uv/hbv/XS+LmijpJrciInVrBrW7fxd4RR9qaZgsF3UwUUQkFLvT8yC4gcBxdSMXEQFiGtTBhZkU1CIiENOgniwXObtY4dxyddCliIgMXCyDutE7Uc0fIiLxDOrGTW7V/CEiEs+grncjP6ozP0RE4hnU9W7kOqAoIhLToG5cmEm35BIRiWdQlwpZCrmMzqUWESGmQW1mTKobuYgIENOghqD5Q93IRURiHdTqnSgiAnEO6lJRbdQiIsQ5qMsFjp5dxN0HXYqIyEDFN6hLBRYrNeaWdL0PEUm3+Aa1zqUWEQFiHdS6MJOICMQ5qEvqRi4iAnEOajV9iIgAcQ5qXZNaRASIcVCP5LOUizk1fYhI6sU2qCG4gYC6kYtI2sU6qNWNXEQk7kFdKnJUBxNFJOViHdST5YIOJopI6sU6qMdLBU7MLVGr6XofIpJesQ7qiXKRSs05fW550KWIiAxM10FtZlkz+1cze6CXBUXVb3KrO72ISJpdyB71u4Ene1VIOxMl9U4UEekqqM1sB3Ab8JHeltNsPOydqBsIiEiadbtH/cfAfwNqnVYws91mNmNmM7OzsxtR20rTh4JaRFJszaA2s13AEXffs9p67n6Pu0+7+/TU1NSGFLetcQU9NX2ISHp1s0d9I/AWM3sW+AzwBjP7ZE+rCuWzGbaO5tU7UURSbc2gdvf/7u473H0n8Fbgq+7+tp5XFhovFdRGLSKpFuvzqAEm1Y1cRFLugoLa3b/u7rt6VUw7E+pGLiIpF/s96uAKetqjFpH0in9Ql4qcXFimUu14ZqCIyFCLf1CXC7jDiXld70NE0in+QV3vRq47vYhISsU/qMv1Ti86oCgi6RT7oK53I9eZHyKSVrEP6nFdQU9EUi72Qb11U56MqelDRNIr9kGdyRjjpaIOJopIasU+qCG8ya32qEUkpRIR1OMldSMXkfRKRFBPlIs6mCgiqZWMoC6p6UNE0isRQT1ZLnBmscJipTroUkRE+i4RQV0/l1o3EBCRNEpEUKsbuYikWSKCunE3ch1QFJEUSkRQN66gpz1qEUmhRAT1eLhHrTZqEUmjRAT1WDFHIZvhqLqRi0gKJSKozSy8d6L2qEUkfRIR1KCb3IpIeiUnqEtFtVGLSColKKgLHFXTh4ikUHKCulzg2Nwi7j7oUkRE+ipBQV3k3HKN+SVd70NE0iU5QV3SudQikk5rBrWZjZjZv5jZ42Z2wMx+rx+FtZpQN3IRSalcF+ssAm9w97Nmlge+YWYPufsjPa6tibqRi0harRnUHhy9OxtO5sNH34/oNa6gp96JIpIyXbVRm1nWzPYCR4Avu/ujbdbZbWYzZjYzOzu7wWVG9qjVRi0iKdNVULt71d1fCewAXmNmL2+zzj3uPu3u01NTUxtcJmwqZBktZNX0ISKpc0Fnfbj7SeDrwC29KGYt6kYuImnUzVkfU2a2NRzfBNwMPNXjutqaKBXV9CEiqdPNWR/bgY+bWZYg2D/r7g/0tqz2JssFDp08N4i3FhEZmG7O+tgHvKoPtaxpvFRg//OnBl2GiEhfJaZnIgTdyI+dXdL1PkQkVZIV1KUClZpzeqEy6FJERPomUUE9Wa6fS60zP0QkPRIV1OOleu9EnfkhIumRqKBudCPXudQikiKJCup604fu9CIiaZKooN42Wt+jVlCLSHokKqgLuQybR3Ic18FEEUmRRAU1BM0fR3UwUURSJHFBrQsziUjaJC+oS0W1UYtIqiQvqMsF3eBWRFIleUFdKnB8folqTdf7EJF0SF5Ql4u4w4l57VWLSDokMKh1LrWIpEvygrqkCzOJSLokL6i1Ry0iKZO8oC7pwkwiki6JC+qtowUypkudikh6JC6osxljvFRQUItIaiQuqCG4gYCaPkQkLRIZ1OpGLiJpksygLqvpQ0TSI5FBPVkuqulDRFIjkUE9Xipw+lyFpUpt0KWIiPRcIoO63ulFV9ETkTRIZlCX6je5VfOHiAy/NYPazK40s6+Z2ZNmdsDM3t2PwlYzqT1qEUmRXBfrVIDfdvfHzGwM2GNmX3b3b/W4to7G693IdWEmEUmBNfeo3f2wuz8Wjp8BngSu6HVhq5koh1fQ07nUIpICF9RGbWY7gVcBj7ZZttvMZsxsZnZ2doPKa2/zSI581jiqoBaRFOg6qM2sDPwN8B53P9263N3vcfdpd5+emprayBrb1cJEqchxNX2ISAp0FdRmlicI6U+5++d6W1J3gut9aI9aRIZfN2d9GPBR4El3v6v3JXVnolzgqM76EJEU6GaP+kbg14A3mNne8HFrj+tak7qRi0harHl6nrt/A7A+1HJBJtT0ISIpkcieiRCcorewXGV+qTLoUkREeiq5QV3STW5FJB2SG9T1u5HrgKKIDLkEB3W9d6IOKIrIcEtuUJe0Ry0i6ZDcoC6rjVpE0iGxQT1ayLEpn1XTh4gMvcQGNegmtyKSDgkP6qKCWkSGXrKDulRQ04eIDL0hCGrtUYvIcEt2UJeLHJtbxN0HXYqISM8kOqgnywWWq86ZRV3vQ0SGV6KDelzX+xCRFEh0UKsbuYikQbKDOtyj1k1uRWSYJTqoJ8M96uM6l1pEhliig3pbKQ+o6UNEhluig7qYyzI2klPvRBEZaokOagiaP45qj1pEhljig3qiVFAbtYgMtcQH9bi6kYvIkEt8UNe7kYuIDKvEB/VkOWj6qNV0vQ8RGU6JD+qJUoGaw8mF5UGXIiLSE8kPanUjF5EhF6+gnj9+wU9RN3IRGXZrBrWZ3WtmR8zsiZ5WsnAS7rkJ/vbdUOk+dBt71DqgKCJDqps96o8Bt/S4DiiOwct/AfZ8DD6+C8682NXTJsq61KmIDLc1g9rdHwYuvE3igivJws2/C7/4f+GF/cHe9fN71nzattECZqgbuYgMrQ1rozaz3WY2Y2Yzs7OzF/9CL/95uPNLkM3BvW+GvX+x6urZjLFtVDe5FZHhtWFB7e73uPu0u09PTU2t78Uuuw7+49fhJT8Gn38HPPReqHa+3ZZucisiwyxeZ31ElSbgbffBj70DHv0QfPLnYO5Y21UnygUdTBSRoRXfoIag+ePNfwA/+yH43qPw4ZuC9usWQTdy7VGLyHDq5vS8TwP/DPyQmR00szt7X1aLV/4K/MZDQfPHR98ET3yuabGaPkRkmHVz1scvu/t2d8+7+w53/2g/CjvPjlfD7q8H7dd//Rvw/34PalUAJkpFTi0ss1SpDaQ0EZFeinfTR6uxS+GOv4Ub7oBv3AWffissnGycS31iXnvVIjJ8khXUALkivOVuuO0u+M5X4SNv5Kra9wF1ehGR4ZS8oK770Tvh1++HhZO87mv/njdm9ujMDxEZSskNaoCdN8Jv/QOVrS/lw/m7mNhzN9TUTi0iwyXZQQ2wZQfn3vYgX6i9jmufuhs+9Dp4+I/gxLODrkxEZEMkP6iBzZvH+K/Vd/LFH3g/jGyBr/4+/Mkr4CM3wyN/1vUFnkRE4mgogtrMGC8VeXjTT8Odfw/v2Q83fwCWF+Dvfgfuugb+/HZ47BPB5VRFRBJkKIIaWm5yu/Ul8BP/Gd7xT/CfHoWf/O2gKeT+d8EfvQw+86tw4L4gyEVEYi436AI2ymS50P4uL5dcA2/4H/BT74PnH4P9fwUHPgdPPQCFMlyzC677Rbj6Jsjm+163iMhahiaoJ0oFnjs233kFs6B3445Xw8/8T3j2G0FoP3k/7PsMjE7AtbfDy94EV0xDeZ1XABQR2SDDE9TlYvfXpM5k4ep/Fzxu+yA885UgtPd+GmbuDdbZ+hK44tVBaO+Yhu2vgPym3n0AEZEOhiaox0sF5paqLCxV2VTIdv/EXBGuuTV4LM3D4cfh+Rk4GD4O3Besl8nBpT+yEtxXTMPED0JmaJr5RSSmhiaoJ+v3TpxbZEdh9OJepDAKV702eNSdeSG4JdjBmSDA930WZsLrUo1sgctvWAnuHdNQmlznJxERaTY0QT1RCu5GfnxuiR3bLjKo2xm7DK65LXhAcMW+o99eCe6De+AfPwge9ogsTcG2ncFj61Ur49t2wubLg2YXEZELMDxB3a+7kWeycMkPB48bfi2YtzQHh/YGe97Hng5OBfz+vwTXzfZq5Ll52Hpl5yDftLW3tYtIIg1PUId71EcHcZPbQim47sjOG5vnV5fh1EE4+VwQ3o3Hc3Do87DQcnP3kS1QviwI7E3bYGRry/i2YLp1PFfo7ecTkYEanqButFHH6FKn2TyMvzR4tHPuVBDa0SCfmw16T54+BEe+FYwvnl79ffKllUDPjwYHSHNFyBaDEK8PcyOQLbRZ1rJ+Jh+sl40O6+OF4MBqfTy6TM06Ij0xNEE9WsiyKZ/lE//8HEuVGruu387VU+VBl7W6kS2w/frgsZpqJQj1cydh4UQQ3tHxhRMr00tzUF2C+XBYWYTqYjCsLK7MizbJbBTLBCFu2XA8OsxGhplgftO8cF2LnEVjVh9pmW43rz704HiB14et4+0ekeXrlclGfsjy3Y1n8+GPY/RHL9/+h7LT/PqyTCb8LPVtEX62+nh0+7Rb7g61SvDwajheDR/R+dFlkSEE9zrNRD9XdDoXfvZ2y/KQH4HiGBQ3B0P9+ANg7r7hLzo9Pe0zMzMb/rpr+cLe5/nkI8/xzWdPAHDt9s3cdv12dl2/nasmSn2vJ9Zq1TC8z0UCfSnyWA4fSyvDWnTeUvAD0rT+UvgfOQy9WnXlP3Vj2GlZLRg2vo/hsHW63bymaVsJ/KZHp/nRB6wE/sXw4HM0ttPyGuPhNoyO17dzPfTSrlBeCe2RzW3GN4fjYbjnRlp+YMLvY9N0+H1r92NkmaC/RGE0+Os0vykcRsajy3KbNuwUXTPb4+7TbZcNU1DXHT61wIP7X+CBfYf41++dBOC6K7aw6/rt3Hrddq4c38CzQkR6oR4k0R/C2nL7H9Ho/HrYmLHyo0U4Hk7XxxvLrXl5Jrfyl0H9L6TGdHR+ZmW8vqyxR17/Qao0/0g1pivtly3Pw+KZ4HHudNDst3g6Mn6meXx5ld7I/ZLbFIZ7Cca2w3/48kW9TOqCOurgiXke3H+YL+47zOMHTwHwyiu3NkL78q3qbSiSWNXlMNjDMK8snv+j0vihiU7ngj3hpulssPe9PB9csG15PugEVx9fXoDluXAYXR5ZJzcCu+66qI+S6qCO+t6xeR7Yf4gv7jvMgUPBAbrpq7ZxWxjal24eGXCFIpJWCuo2vjt7lgf3H+aBfYd56oUzmMGP7hzn1VdtY/uWES7bPML2LZu4bMsIE6UCmcx62i5FRFanoF7DM0fO8MV9L/DQE4f5zuxZlqvN2ySfNS7dPBIE+JZNkSAf4bItQaBPjRXJKsxF5CIpqC9AreYcm1vihVPnOHxqgRdOn+PwqXMr06eC6cVK86lc2YxxyViRraMFSoUspWKOcjFHqbgyPlrIUQ6nV5bnGuuXijlG8hkK2QxmCn2RNFktqIfmPOqNkskYU2NFpsaKXLdjS9t13J2T88tBgJ9eaAT5oZPnOLWwzNxihRPzS3z/xDzzi1XmFiucXapwIb+J+axRyGYo5DLkw2Ehl2meFxkvhstzGSOXNbIZI5fJhMP6vGB5fV5jmM2QD6ezGSNjhhlkLBjPZoLbnQXT4fzMynh03YzV112Z11ieAWOVdTLWODnOLFg3GBKclBCZNrNwGMxvnLTQeH7z8vrvXuvrNq2nH0eJKQX1RTAztpUKbCsVuPbyzV09x91ZWK5ydrHCXBjec4sV5pYqnI1ML1ZqLFZqLFdrLFWCR2M8MqzPm1+ohutVWarWqFadSs2p1oJhpVprmpaL0y7DO8V6PfCjPzrBdGNk1eXR92rq4hNZ0PTeLYVYZF07773svPeF9uueX4t1mN9Z6zeudWfFz1ujPWvzLp1+V6Ofv75edBtHP2fTv1Wbz9/29Vf5QR8fLfDZt7+24/KL1VVQm9ktwJ8AWeAj7v4HG17JkDMzRgtB8wdjg6nB3ak5VGq1SJD7ynTVqYXr1Nxxd6o1wnkenCLrQejXfOX16str0XXr79eY17x+Y3nL84I6CZcH/5Hr0zSeFzzXm9b1yOdsfl50ur4dOr5H+w13/qw1Vq0H0Mp0++Wct7z5c7R7v+b5zZU0Latvz8iyteqKvlPza7V/z/OD9/yga8211tBd6w+Zdn+Jdgr46L9j4/NGPmt0m3iH+asXs/risZHe7Puu+apmlgX+FPhp4CDwTTO7392/1ZOKpGfMjKxBVt1yRRKlm76PrwGecffvuvsS8Bng9t6WJSIidd0E9RXA9yPTB8N5Tcxst5nNmNnM7OzsRtUnIpJ63QR1uxak81pq3P0ed5929+mpKd3BW0Rko3QT1AeBKyPTO4BDvSlHRERadRPU3wReZmYvNbMC8Fbg/t6WJSIidWue9eHuFTN7F/D3BKfn3evuB3pemYiIAF2eR+3uDwIP9rgWERFpY2NuTSAiIj3Tk4symdks8NxFPn0SOLqB5Ww01bc+qm99VN/6xLm+q9y97SlzPQnq9TCzmU5XkIoD1bc+qm99VN/6xL2+TtT0ISIScwpqEZGYi2NQ3zPoAtag+tZH9a2P6lufuNfXVuzaqEVEpFkc96hFRCRCQS0iEnMDCWozu8XM/s3MnjGz97ZZbmZ2d7h8n5nd0Of6rjSzr5nZk2Z2wMze3Wadm8zslJntDR/v73ONz5rZ/vC9z7uT8CC3oZn9UGS77DWz02b2npZ1+rr9zOxeMztiZk9E5o2b2ZfN7OlwuK3Dc1f9vvawvv9tZk+F/373mdnWDs9d9bvQw/o+YGbPR/4Nb+3w3EFtv7+M1Pasme3t8Nyeb7918/CWS/16EFwv5DvA1UABeBy4tmWdW4GHCC6x+uPAo32ucTtwQzg+Bny7TY03AQ/0e/tF3v9ZYHKV5QPdhi3/3i8QnMw/sO0HvB64AXgiMu9/Ae8Nx98L/GGH+lf9vvawvjcBuXD8D9vV1813oYf1fQD4L138+w9k+7Us/yDw/kFtv/U+BrFH3c0dY24H/twDjwBbzWx7vwp098Pu/lg4fgZ4kjY3S4i5gW7DiDcC33H3i+2puiHc/WHgeMvs24GPh+MfB362zVP7coejdvW5+5fcvRJOPkJwieGB6LD9ujGw7Vdnwd1ofwn49Ea/b78MIqi7uWNMV3eV6Qcz2wm8Cni0zeLXmtnjZvaQmf1IfyvDgS+Z2R4z291meVy24Vvp/B9kkNsP4FJ3PwzBjzNwSZt14rIdf5PgL6R21vou9NK7wqaZezs0HcVh+/0k8KK7P91h+SC3X1cGEdTd3DGmq7vK9JqZlYG/Ad7j7qdbFj9G8Of8K4D/A3y+z+Xd6O43AG8G3mlmr29ZPvBtaMH1y98C/FWbxYPeft2Kw3Z8H1ABPtVhlbW+C73yIeAHgFcChwmaF1oNfPsBv8zqe9OD2n5dG0RQd3PHmIHfVcbM8gQh/Sl3/1zrcnc/7e5nw/EHgbyZTfarPnc/FA6PAPcR/IkZNfBtSPDFf8zdX2xdMOjtF3qx3hwUDo+0WWeg29HM7gB2Ab/qYYNqqy6+Cz3h7i+6e9Xda8CHO7zvoLdfDvh54C87rTOo7XchBhHU3dwx5n7g18MzF34cOFX/E7UfwjatjwJPuvtdHda5LFwPM3sNwbY81qf6SmY2Vh8nOOj0RMtqA92GoY57MoPcfhH3A3eE43cAX2izzsDucGRmtwC/A7zF3ec7rNPNd6FX9UWPefxch/cd9B2ibgaecveD7RYOcvtdkEEcwSQ4I+HbBEeD3xfOezvw9nDcgD8Nl+8Hpvtc308Q/Hm2D9gbPm5tqfFdwAGCo9iPAK/rY31Xh+/7eFhDHLfhKEHwbonMG9j2I/jBOAwsE+zl3QlMAF8Bng6H4+G6lwMPrvZ97VN9zxC079a/g3/WWl+n70Kf6vtE+N3aRxC+2+O0/cL5H6t/5yLr9n37rfehLuQiIjGnnokiIjGnoBYRiTkFtYhIzCmoRURiTkEtIhJzCmoRkZhTUIuIxNz/Bz0sFbAVvFA9AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mod_loss = output.history['loss']\n",
    "mod_val_loss = output.history['val_loss']\n",
    "plt.plot(mod_loss, label='mod_loss')\n",
    "plt.plot(mod_val_loss, label='mod_val_loss')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b807fa54",
   "metadata": {},
   "source": [
    "We build our final ouput vector by inverting the to_categorical to associate a class number with every pixel. Since we don't have a y_test to compare with our predict output, we predict the train set and compare it with our y_train to check the precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6ceced78",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_acc=model.predict(train_set_x_flatten)\n",
    "yb=[]\n",
    "for i in range(y_train_acc.shape[0]):\n",
    "    yb.append(np.argmax(y_train_acc[i,:]))\n",
    "a=np.array(yb)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "761f9ced",
   "metadata": {},
   "source": [
    "We print the accuracy of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9612c4a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  85.62903225806451 %\n"
     ]
    }
   ],
   "source": [
    "e=0\n",
    "for i in range(len(a)):\n",
    "    if a[i] == train_set_y_flatten[i]:\n",
    "        e=e+1\n",
    "print(\"Precision: \",e/len(a)*100,\"%\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2934b9e5",
   "metadata": {},
   "source": [
    "Now that we have the accuracy of our model, we build the predict model of the x_test. We store our vector into a csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "680725c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3012\n"
     ]
    }
   ],
   "source": [
    "y_test=model.predict(test_set_x_flatten)\n",
    "yt=[]\n",
    "for i in range(y_test.shape[0]):\n",
    "    yt.append(np.argmax(y_test[i,:]))\n",
    "sample=np.array(yt)\n",
    "sample=sample.reshape(len(sample),1)\n",
    "s = np.linspace(0,len(sample)-1,len(sample))\n",
    "s=s.reshape(len(s),1)\n",
    "sample1 = np.concatenate((s,sample),axis=1)\n",
    "np.savetxt('a.csv',sample1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
